{
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "PROJECT=!gcloud config get-value project\nPROJECT=PROJECT[0]\nBUCKET = PROJECT + '-dsongcp'\nimport os\nos.environ['BUCKET'] = PROJECT + '-dsongcp'",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "from pyspark.sql import SparkSession\nfrom pyspark import SparkContext\nsc = SparkContext('local', 'logistic')\nspark = SparkSession \\\n    .builder \\\n    .appName(\"Logistic regression w/ Spark ML\") \\\n    .getOrCreate()",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "from pyspark.mllib.classification import LogisticRegressionWithLBFGS\nfrom pyspark.mllib.regression import LabeledPoint",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "traindays = spark.read \\\n    .option(\"header\", \"true\") \\\n    .csv('gs://{}/flights/trainday.csv'.format(BUCKET))\ntraindays.createOrReplaceTempView('traindays')",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "traindays.createOrReplaceTempView('traindays')",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "spark.sql(\"SELECT * from traindays LIMIT 5\").show()",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "inputs = 'gs://{}/flights/tzcorr/all_flights-00000-*'.format(BUCKET)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "flights = spark.read.json(inputs)\nflights.createOrReplaceTempView('flights')",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "trainquery = \"\"\"\nSELECT\n  DEP_DELAY, TAXI_OUT, ARR_DELAY, DISTANCE\nFROM flights f\nJOIN traindays t\nON f.FL_DATE == t.FL_DATE\nWHERE\n  t.is_train_day == 'True'\n\"\"\"\ntraindata = spark.sql(trainquery)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "print(traindata.head(2))",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "traindata.describe().show()",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "trainquery = \"\"\"\nSELECT\nDEP_DELAY, TAXI_OUT, ARR_DELAY, DISTANCE\nFROM flights f\nJOIN traindays t\nON f.FL_DATE == t.FL_DATE\nWHERE\nt.is_train_day == 'True' AND\nf.dep_delay IS NOT NULL AND \nf.arr_delay IS NOT NULL\n\"\"\"\ntraindata = spark.sql(trainquery)\ntraindata.describe().show()",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "trainquery = \"\"\"\nSELECT\n  DEP_DELAY, TAXI_OUT, ARR_DELAY, DISTANCE\nFROM flights f\nJOIN traindays t\nON f.FL_DATE == t.FL_DATE\nWHERE\n  t.is_train_day == 'True' AND\n  f.CANCELLED == 'False' AND \n  f.DIVERTED == 'False'\n\"\"\"\ntraindata = spark.sql(trainquery)\ntraindata.describe().show()",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "def to_example(fields):\n    return LabeledPoint(\\\n              float(fields['ARR_DELAY'] < 15), #ontime? \\\n              [ \\\n                  fields['DEP_DELAY'], \\\n                  fields['TAXI_OUT'],  \\\n                  fields['DISTANCE'],  \\\n              ])",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "examples = traindata.rdd.map(to_example)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "lrmodel = LogisticRegressionWithLBFGS.train(examples, intercept=True)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "print(lrmodel.weights,lrmodel.intercept)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "print(lrmodel.predict([6.0,12.0,594.0]))",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "print(lrmodel.predict([36.0,12.0,594.0]))",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "lrmodel.clearThreshold()\nprint(lrmodel.predict([6.0,12.0,594.0]))\nprint(lrmodel.predict([36.0,12.0,594.0]))",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "lrmodel.setThreshold(0.7) \nprint(lrmodel.predict([6.0,12.0,594.0]))\nprint(lrmodel.predict([36.0,12.0,594.0]))",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "MODEL_FILE='gs://' + BUCKET + '/flights/sparkmloutput/model'\nos.system('gsutil -m rm -r ' + MODEL_FILE)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "lrmodel.save(sc, MODEL_FILE)\nprint('{} saved'.format(MODEL_FILE))",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "lrmodel = 0\nprint(lrmodel)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "from pyspark.mllib.classification import LogisticRegressionModel\nlrmodel = LogisticRegressionModel.load(sc, MODEL_FILE)\nlrmodel.setThreshold(0.7)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}